  <img src="https://github.com/Stenke/B-Bot-Question-Answering/blob/main/Images/Screen%20Shot%202021-03-02%20at%204.39.38%20PM.png" width="500"   length="700" />

## BERT-Based QA Model with Curated Datasets and ElasticSearch in Mind

Ada.ai aims to reduce human bias by scaling vulnerable questions and honest answers provided by professionals. Using a question-answering model based on the BERT model and fine-tuned on the SQuAD 2.0 dataset. Next steps include domain-specific QA datasets for fine-tuning, long-form context scripts sourced from podcast transcripts and online articles, and an ElasticSearch framework for document retrieval best suited for answering a user's question.

## Current Problem
The first two decades of this century showed us the risks of siloed dialogue.
Countless events surprised some portion of the population - the truth being hidden in plain sight.
Yet, even after we acknowledged the misalignment, words were left unsaid.

##### The problem is weâ€™re afraid to ask the questions that matter.
<br /> <br />

There are wonderful podcasts, books, and blogs that address some of the most sensitive issues: sex, race, religion, politics, etc.
Though these are great resources, they lack the intimacy of dialogue and the self-reflection inherent in asking a vulnerable question.
Ada.ai intends to promote these conversations at scale.


# The Data
Data was sourced from Twitter using Twint. The accounts were selected for their ecletic humor, inspirational quotes, and emotional intelligence. <br /> <br />
The following accounts were sourced to fine-tune our GPT-2 language model:
1. Simon Sinek
2. Brene Brown
3. Conan O'Brien
4. Lex Fridman
5. Tim Siedell
6. Dalai Lama
7. Pourmecoffee
8. Steve Martin
